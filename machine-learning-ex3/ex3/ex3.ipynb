{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load 'ex3.m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%% Machine Learning Online Class - Exercise 3 | Part 1: One-vs-all\n",
    "\n",
    "%  Instructions\n",
    "%  ------------\n",
    "% \n",
    "%  This file contains code that helps you get started on the\n",
    "%  linear exercise. You will need to complete the following functions \n",
    "%  in this exericse:\n",
    "%\n",
    "%     lrCostFunction.m (logistic regression cost function)\n",
    "%     oneVsAll.m\n",
    "%     predictOneVsAll.m\n",
    "%     predict.m\n",
    "%\n",
    "%  For this exercise, you will not need to change any code in this file,\n",
    "%  or any other files other than those mentioned above.\n",
    "%\n",
    "\n",
    "%% Initialization\n",
    "clear ; close all; clc\n",
    "\n",
    "%% Setup the parameters you will use for this part of the exercise\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10   \n",
    "                          % (note that we have mapped \"0\" to label 10)\n",
    "\n",
    "%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset. \n",
    "%  You will be working with a dataset that contains handwritten digits.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading and Visualizing Data ...\\n')\n",
    "\n",
    "load('ex3data1.mat'); % training data stored in arrays X, y\n",
    "m = size(X, 1);\n",
    "\n",
    "% Randomly select 100 data points to display\n",
    "rand_indices = randperm(m);\n",
    "sel = X(rand_indices(1:100), :);\n",
    "\n",
    "displayData(sel);\n",
    "\n",
    "fprintf('Program paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "%% ============ Part 2: Vectorize Logistic Regression ============\n",
    "%  In this part of the exercise, you will reuse your logistic regression\n",
    "%  code from the last exercise. You task here is to make sure that your\n",
    "%  regularized logistic regression implementation is vectorized. After\n",
    "%  that, you will implement one-vs-all classification for the handwritten\n",
    "%  digit dataset.\n",
    "%\n",
    "\n",
    "fprintf('\\nTraining One-vs-All Logistic Regression...\\n')\n",
    "\n",
    "lambda = 0.1;\n",
    "[all_theta] = oneVsAll(X, y, num_labels, lambda);\n",
    "\n",
    "fprintf('Program paused. Press enter to continue.\\n');\n",
    "pause;\n",
    "\n",
    "\n",
    "%% ================ Part 3: Predict for One-Vs-All ================\n",
    "%  After ...\n",
    "pred = predictOneVsAll(all_theta, X);\n",
    "\n",
    "fprintf('\\nTraining Set Accuracy: %f\\n', mean(double(pred == y)) * 100);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "clear ; close all; clc\n",
    "\n",
    "%%% Setup the parameters you will use for this part of the exercise\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10   \n",
    "                          % (note that we have mapped \"0\" to label 10)\n",
    "\n",
    "%%% =========== Part 1: Loading and Visualizing Data =============\n",
    "%  We start the exercise by first loading and visualizing the dataset. \n",
    "%  You will be working with a dataset that contains handwritten digits.\n",
    "%\n",
    "\n",
    "% Load Training Data\n",
    "fprintf('Loading and Visualizing Data ...\\n')\n",
    "\n",
    "load('ex3data1.mat'); % training data stored in arrays X, y\n",
    "m = size(X, 1);\n",
    "\n",
    "% Randomly select 100 data points to display\n",
    "rand_indices = randperm(m);\n",
    "sel = X(rand_indices(1:100), :);\n",
    "\n",
    "displayData(sel);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clear ; close all; clc\n",
    "input_layer_size  = 400;  % 20x20 Input Images of Digits\n",
    "num_labels = 10;          % 10 labels, from 1 to 10   \n",
    "\n",
    "fprintf('Loading and Visualizing Data ...\\n')\n",
    "\n",
    "load('ex3data1.mat'); % training data stored in arrays X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagesc(reshape(X(1,:)/max1,20,20), [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function showNum(X, bg_rows= 8)\n",
    "% showNum displays a grid of random images of numbers\n",
    "% ex is the starting number\n",
    "    ex = 1\n",
    "    m = size(X, 1); % get number of examples (rows)\n",
    "    rand_indices = randperm(m);\n",
    "    X = X(rand_indices(1:(bg_rows^2)), :);\n",
    "    \n",
    "    img_wh = 20;\n",
    "    \n",
    "    bg = ones(bg_rows * img_wh,img_wh);\n",
    "    \n",
    "    for i = ex:(ex+bg_rows-1) % show 3 examples \n",
    "        for j = ex:(ex + bg_rows -1)\n",
    "            colormap(gray)\n",
    "            r = X(j + bg_rows* (i-ex),:);\n",
    "            r = r / max(abs(r)); % all values between -1 and 1\n",
    "            offsetx = (i-ex)*img_wh;\n",
    "            offsety = (j-ex)*img_wh;\n",
    "            bg( (1:img_wh) + offsetx , (1:img_wh) + offsety) =  flipud(reshape(r,img_wh,img_wh));\n",
    "        end\n",
    "    end\n",
    "    imagesc(bg, [-1,1]);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showNum(X,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file displayData.m\n",
    "function [h, display_array] = displayData(X, example_width)\n",
    "%%%DISPLAYDATA Display 2D data in a nice grid\n",
    "%%%   [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data\n",
    "%%%   stored in X in a nice grid. It returns the figure handle h and the \n",
    "%%%   displayed array if requested.\n",
    "\n",
    "\n",
    "% Set example_width automatically if not passed in\n",
    "if ~exist('example_width', 'var') || isempty(example_width) \n",
    "\texample_width = round(sqrt(size(X, 2)));\n",
    "end\n",
    "\n",
    "% Gray Image\n",
    "colormap(gray);\n",
    "\n",
    "% Compute rows, cols\n",
    "[m n] = size(X);\n",
    "example_height = (n / example_width);\n",
    "\n",
    "% Compute number of items to display\n",
    "display_rows = floor(sqrt(m));\n",
    "display_cols = ceil(m / display_rows);\n",
    "\n",
    "% Between images padding\n",
    "pad = 1;\n",
    "\n",
    "% Setup blank display\n",
    "display_array = - ones(pad + display_rows * (example_height + pad), ...\n",
    "                       pad + display_cols * (example_width + pad));\n",
    "\n",
    "% Copy each example into a patch on the display array\n",
    "curr_ex = 1;\n",
    "for j = 1:display_rows\n",
    "\tfor i = 1:display_cols\n",
    "\t\tif curr_ex > m, \n",
    "\t\t\t%break; \n",
    "\t\tend\n",
    "\t\t% Copy the patch\n",
    "\t\t\n",
    "\t\t% Get the max value of the patch\n",
    "\t\tmax_val = max(abs(X(curr_ex, :)));\n",
    "\t\tdisplay_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ...\n",
    "\t\t              pad + (i - 1) * (example_width + pad) + (1:example_width)) = ...\n",
    "\t\t\t\t\t\treshape(X(curr_ex, :), example_height, example_width) / max_val;\n",
    "\t\tcurr_ex = curr_ex + 1;\n",
    "\tend\n",
    "\tif curr_ex > m, \n",
    "\t\t%break; \n",
    "\tend\n",
    "end\n",
    "\n",
    "% Display Image\n",
    "\n",
    "h = imagesc(display_array, CLIMITS= [-1 1]);\n",
    "\n",
    "% Do not show axis\n",
    "axis image off\n",
    "\n",
    "%%%%drawnow;\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% Gray Image\n",
    "colormap(gray);\n",
    "imagesc(1- ((2*eye(100)-1)),[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load lrCostFunction.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file lrCostFunction.m\n",
    "function [J, grad] = lrCostFunction(theta, X, y, lambda=0)\n",
    "%LRCOSTFUNCTION Compute cost and gradient for logistic regression with \n",
    "%regularization\n",
    "%   J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using\n",
    "%   theta as the parameter for regularized logistic regression and the\n",
    "%   gradient of the cost w.r.t. to the parameters. \n",
    "\n",
    "% Initialize some useful values\n",
    "%% m = length(y); % number of training examples\n",
    "[m,n] = size(X) ;\n",
    "% You need to return the following variables correctly \n",
    "J = 0;\n",
    "grad = zeros(size(theta));\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Compute the cost of a particular choice of theta.\n",
    "%               You should set J to the cost.\n",
    "%               Compute the partial derivatives and set grad to the partial\n",
    "%               derivatives of the cost w.r.t. each parameter in theta\n",
    "%\n",
    "% Hint: The computation of the cost function and gradients can be\n",
    "%       efficiently vectorized. For example, consider the computation\n",
    "%\n",
    "%           sigmoid(X * theta)\n",
    "%\n",
    "%       Each row of the resulting matrix will contain the value of the\n",
    "%       prediction for that example. You can make use of this to vectorize\n",
    "%       the cost function and gradient computations. \n",
    "%\n",
    "% Hint: When computing the gradient of the regularized cost function, \n",
    "%       there're many possible vectorized solutions, but one solution\n",
    "%       looks like:\n",
    "%           grad = (unregularized gradient for logistic regression)\n",
    "%           temp = theta; \n",
    "%           temp(1) = 0;   % because we don't add anything for j = 0  \n",
    "%           grad = grad + YOUR_CODE_HERE (using the temp variable)\n",
    "%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[m,n] = size(X);\n",
    "J = sum(-   y  .*log(    sigmoid(X * theta)) \n",
    "        - (1-y).*log(1 - sigmoid(X * theta))\n",
    "        ) / m + lambda / (2*m) * theta(2:3)'*theta(2:3);\n",
    "\n",
    "\n",
    "\n",
    "g1 =  sum((sigmoid(X * theta) - y) .* X(:,1))/ m ;\n",
    "g2na = sum((sigmoid(X * theta) - y) .* X(:,2:n))/ m ;\n",
    "g2nb = lambda / m * theta(2:n)  ;\n",
    "\n",
    "grad = [g1,g2na + g2nb'] ;\n",
    "\n",
    "% =============================================================\n",
    "\n",
    "grad = grad(:);\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load oneVsAll.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file oneVsAll.m\n",
    "function [all_theta] = oneVsAll(X, y, num_labels, lambda)\n",
    "%ONEVSALL trains multiple logistic regression classifiers and returns all\n",
    "%the classifiers in a matrix all_theta, where the i-th row of all_theta \n",
    "%corresponds to the classifier for label i\n",
    "%   [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels\n",
    "%   logistic regression classifiers and returns each of these classifiers\n",
    "%   in a matrix all_theta, where the i-th row of all_theta corresponds \n",
    "%   to the classifier for label i\n",
    "\n",
    "% Some useful variables\n",
    "m = size(X, 1);\n",
    "n = size(X, 2);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "all_theta = zeros(num_labels, n + 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: You should complete the following code to train num_labels\n",
    "%               logistic regression classifiers with regularization\n",
    "%               parameter lambda. \n",
    "%\n",
    "% Hint: theta(:) will return a column vector.\n",
    "%\n",
    "% Hint: You can use y == c to obtain a vector of 1's and 0's that tell use \n",
    "%       whether the ground truth is true/false for this class.\n",
    "%\n",
    "% Note: For this assignment, we recommend using fmincg to optimize the cost\n",
    "%       function. It is okay to use a for-loop (for c = 1:num_labels) to\n",
    "%       loop over the different classes.\n",
    "%\n",
    "%       fmincg works similarly to fminunc, but is more efficient when we\n",
    "%       are dealing with large number of parameters.\n",
    "%\n",
    "% Example Code for fmincg:\n",
    "%\n",
    "%     % Set Initial theta\n",
    "%     initial_theta = zeros(n + 1, 1);\n",
    "%     \n",
    "%     % Set options for fminunc\n",
    "%     options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "% \n",
    "%     % Run fmincg to obtain the optimal theta\n",
    "%     % This function will return theta and the cost \n",
    "%     [theta] = ...\n",
    "%         fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...\n",
    "%                 initial_theta, options);\n",
    "%\n",
    "    initial_theta = zeros(n + 1, 1);\n",
    "    options = optimset('GradObj', 'on', 'MaxIter', 50);\n",
    "    for k = 1:num_labels\n",
    "        all_theta(k,:) = fmincg (@(t)(lrCostFunction(t, X, (y == k), lambda)), initial_theta, options);       \n",
    "    end    \n",
    "    r = all_theta\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xm = [ -1 -1 ; -1 -2 ; -2 -1 ; -2 -2 ; ...\n",
    "          1 1 ;  1 2 ;  2 1 ; 2 2 ; ...\n",
    "         -1 1 ;  -1 2 ;  -2 1 ; -2 2 ; ...\n",
    "          1 -1 ; 1 -2 ;  -2 -1 ; -2 -2 ];\n",
    "ym = [ 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 ]';\n",
    "sprintf('%0.5f ', oneVsAll(Xm, ym, 4, 0.1));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size(ym == 3)\n",
    "X = [ones(20,1) (exp(1) * sin(1:1:20))' (exp(0.5) * cos(1:1:20))'];\n",
    "size(sin(X(:,1) + X(:,2)) > 0)\n",
    "t1 = sin(reshape(1:2:24, 4, 3));\n",
    "t2 = cos(reshape(1:2:40, 4, 5));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load submit.m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:\n",
    "\n",
    "$L$, a learner (training algorithm for binary classifiers)\n",
    "samples $X$\n",
    "\n",
    "labels $y$ where $y_i \\in  \\{1, … K\\}$ is the label for the sample $X_i$\n",
    "\n",
    "Output:\n",
    "\n",
    "a list of classifiers $f_k$ for $k \\in \\{1, …, K\\}$\n",
    "\n",
    "Procedure:\n",
    "\n",
    "For each $k$ in $\\{1, …, K\\}$:\n",
    "\n",
    "Construct a new label vector $y_i = 1$ where $y_i = k, 0 (or −1)$ elsewhere\n",
    "\n",
    "Apply $L$ to $X, y$ to obtain $f_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load predictOneVsAll.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file predictOneVsAll.m\n",
    "function p = predictOneVsAll(all_theta, X)\n",
    "%PREDICT Predict the label for a trained one-vs-all classifier. The labels \n",
    "%are in the range 1..K, where K = size(all_theta, 1). \n",
    "%  p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions\n",
    "%  for each example in the matrix X. Note that X contains the examples in\n",
    "%  rows. all_theta is a matrix where the i-th row is a trained logistic\n",
    "%  regression theta vector for the i-th class. You should set p to a vector\n",
    "%  of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2\n",
    "%  for 4 examples) \n",
    "\n",
    "m = size(X, 1);\n",
    "num_labels = size(all_theta, 1);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "p = zeros(size(X, 1), 1);\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the following code to make predictions using\n",
    "%               your learned logistic regression parameters (one-vs-all).\n",
    "%               You should set p to a vector of predictions (from 1 to\n",
    "%               num_labels).\n",
    "%\n",
    "% Hint: This code can be done all vectorized using the max function.\n",
    "%       In particular, the max function can also return the index of the \n",
    "%       max element, for more information see 'help max'. If your examples \n",
    "%       are in rows, then, you can use max(A, [], 2) to obtain the max \n",
    "%       for each row.\n",
    "%       \n",
    "\n",
    "% i should be a vector containing the maximum for each sample in X\n",
    "% all \n",
    "[v,p] = max(sigmoid(all_theta * X'))\n",
    "\n",
    "p = p'\n",
    "\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[v,i] = max(reshape(1:24,6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file '/Users/jlatmann/Programming/octave/machine-learning-ex3/ex3/predict.m'.\n"
     ]
    }
   ],
   "source": [
    "%%file predict.m\n",
    "function p = predict(Theta1, Theta2, X)\n",
    "%PREDICT Predict the label of an input given a trained neural network\n",
    "%   p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the\n",
    "%   trained weights of a neural network (Theta1, Theta2)\n",
    "\n",
    "% Useful values\n",
    "m = size(X, 1);\n",
    "num_labels = size(Theta2, 1);\n",
    "\n",
    "% You need to return the following variables correctly \n",
    "p = zeros(size(X, 1), 1);\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% Instructions: Complete the following code to make predictions using\n",
    "%               your learned neural network. You should set p to a \n",
    "%               vector containing labels between 1 to num_labels.\n",
    "%\n",
    "% Hint: The max function might come in useful. In particular, the max\n",
    "%       function can also return the index of the max element, for more\n",
    "%       information see 'help max'. If your examples are in rows, then, you\n",
    "%       can use max(A, [], 2) to obtain the max for each row.\n",
    "%\n",
    "\n",
    "\n",
    "% Add ones to the X data matrix\n",
    "X = [ones(m, 1) X];\n",
    "[m,n] = size(X)\n",
    "\n",
    "a1 = sigmoid(Theta1 * X') % \n",
    "\n",
    "a1p = [ones(m,1)'; a1]\n",
    "\n",
    "[v,p] = max(sigmoid(Theta2 * a1p))\n",
    "p = p';\n",
    "\n",
    "% =========================================================================\n",
    "\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: Neural Networks - learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ans =\r\n",
       "\r\n",
       "   1   1   1   1   1   1\r\n",
       "   1   1   1   1   1   1\r\n",
       "   1   1   1   1   1   1\r\n",
       "   1   1   1   1   1   1\r\n",
       "\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape(([zeros(5,3)(:);ones(4,6)(:)](16:39)),4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eps =  0.010000\r\n",
       "theta =  1\r\n",
       "cost =  1.0303\r\n",
       "cost =  0.97030\r\n",
       "ans =  3.0001\r\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cost = J(theta)\n",
    "    cost = theta^3 \n",
    "end\n",
    "\n",
    "eps = 0.01\n",
    "theta = 1\n",
    "(J(theta + eps) - J(theta - eps)) / (2*eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave_kernel"
  },
  "language_info": {
   "codemirror_mode": "Octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave_kernel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
